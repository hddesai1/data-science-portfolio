{
 "cells": [
  {
   "source": "# Iterating on LLM Apps with TruLens\n\nOur simple RAG often struggles with retrieving not enough information from the insurance manual to properly answer the question. The information needed may be just outside the chunk that is identified and retrieved by our app. Reducing the size of the chunk and adding \"sentence windows\" to our retrieval is an advanced RAG technique that can help with retrieving more targeted, complete context. Here we can try this technique, and test its success with TruLens.",
   "metadata": {},
   "id": "03ccd61b-ca55-4ff0-8481-ac07523b5029",
   "cell_type": "markdown"
  },
  {
   "source": [
    "i",
    "m",
    "p",
    "o",
    "r",
    "t",
    " ",
    "o",
    "p",
    "e",
    "n",
    "a",
    "i",
    "\n",
    "f",
    "r",
    "o",
    "m",
    " ",
    "t",
    "r",
    "u",
    "l",
    "e",
    "n",
    "s",
    "_",
    "e",
    "v",
    "a",
    "l",
    " ",
    "i",
    "m",
    "p",
    "o",
    "r",
    "t",
    " ",
    "T",
    "r",
    "u",
    "\n",
    "t",
    "r",
    "u",
    " ",
    "=",
    " ",
    "T",
    "r",
    "u",
    "(",
    "d",
    "a",
    "t",
    "a",
    "b",
    "a",
    "s",
    "e",
    "_",
    "r",
    "e",
    "d",
    "a",
    "c",
    "t",
    "_",
    "k",
    "e",
    "target",
    "s",
    "=",
    "T",
    "r",
    "u",
    "e",
    ")"
   ],
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "id": "76434568-9f5d-40a7-8048-f71ccaabd1da",
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\nðŸ”’ Secret keys will not be included in the database.\n"
    }
   ]
  },
  {
   "source": "## Load data and test set",
   "metadata": {},
   "id": "779f2438-60d4-4475-a2ca-206bc0fc641b",
   "cell_type": "markdown"
  },
  {
   "source": [
    "f",
    "r",
    "o",
    "m",
    " ",
    "l",
    "l",
    "a",
    "m",
    "a",
    "_",
    "h",
    "u",
    "b",
    ".",
    "s",
    "m",
    "a",
    "r",
    "t",
    "_",
    "p",
    "d",
    "f",
    "_",
    "l",
    "o",
    "a",
    "d",
    "e",
    "r",
    " ",
    "i",
    "m",
    "p",
    "o",
    "r",
    "t",
    " ",
    "S",
    "m",
    "a",
    "r",
    "t",
    "P",
    "D",
    "F",
    "L",
    "o",
    "a",
    "d",
    "e",
    "r",
    "\n",
    "\n",
    "l",
    "l",
    "m",
    "s",
    "h",
    "e",
    "r",
    "p",
    "a",
    "_",
    "a",
    "p",
    "i",
    "_",
    "u",
    "r",
    "l",
    " ",
    "=",
    " ",
    "\"",
    "h",
    "t",
    "t",
    "p",
    "s",
    ":",
    "/",
    "/",
    "r",
    "e",
    "a",
    "d",
    "e",
    "r",
    "s",
    ".",
    "l",
    "l",
    "m",
    "s",
    "h",
    "e",
    "r",
    "p",
    "a",
    ".",
    "c",
    "o",
    "m",
    "/",
    "a",
    "p",
    "i",
    "/",
    "d",
    "o",
    "c",
    "u",
    "m",
    "e",
    "n",
    "t",
    "/",
    "d",
    "e",
    "v",
    "e",
    "l",
    "o",
    "p",
    "e",
    "r",
    "/",
    "p",
    "a",
    "r",
    "s",
    "e",
    "D",
    "o",
    "c",
    "u",
    "m",
    "e",
    "n",
    "t",
    "?",
    "r",
    "e",
    "n",
    "d",
    "e",
    "r",
    "F",
    "o",
    "r",
    "m",
    "a",
    "t",
    "=",
    "a",
    "l",
    "l",
    "\"",
    "\n",
    "p",
    "d",
    "f",
    "_",
    "l",
    "o",
    "a",
    "d",
    "e",
    "r",
    " ",
    "=",
    " ",
    "S",
    "m",
    "a",
    "r",
    "t",
    "P",
    "D",
    "F",
    "L",
    "o",
    "a",
    "d",
    "e",
    "r",
    "(",
    "l",
    "l",
    "m",
    "s",
    "h",
    "e",
    "r",
    "p",
    "a",
    "_",
    "a",
    "p",
    "i",
    "_",
    "u",
    "r",
    "l",
    "=",
    "l",
    "l",
    "m",
    "s",
    "h",
    "e",
    "r",
    "p",
    "a",
    "_",
    "a",
    "p",
    "i",
    "_",
    "u",
    "r",
    "l",
    ")",
    "\n",
    "\n",
    "d",
    "o",
    "c",
    "u",
    "m",
    "e",
    "n",
    "t",
    "s",
    " ",
    "=",
    " ",
    "p",
    "d",
    "f",
    "_",
    "l",
    "o",
    "a",
    "d",
    "e",
    "r",
    ".",
    "l",
    "o",
    "a",
    "d",
    "_",
    "d",
    "a",
    "t",
    "a",
    "(",
    "\"",
    "h",
    "t",
    "t",
    "p",
    "s",
    ":",
    "/",
    "/",
    "w",
    "w",
    "w",
    ".",
    "i",
    "i",
    "i",
    ".",
    "o",
    "r",
    "g",
    "/",
    "s",
    "i",
    "t",
    "e",
    "s",
    "/",
    "d",
    "e",
    "f",
    "a",
    "u",
    "l",
    "t",
    "/",
    "f",
    "i",
    "l",
    "e",
    "s",
    "/",
    "d",
    "o",
    "c",
    "s",
    "/",
    "p",
    "d",
    "f",
    "/",
    "I",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    "_",
    "H",
    "a",
    "n",
    "d",
    "b",
    "o",
    "o",
    "k",
    "_",
    "2",
    "0",
    "1",
    "0",
    "3",
    ".",
    "p",
    "d",
    "f",
    "\"",
    ")",
    "\n",
    "\n",
    "#",
    " ",
    "L",
    "o",
    "a",
    "d",
    " ",
    "s",
    "o",
    "m",
    "e",
    " ",
    "q",
    "u",
    "e",
    "s",
    "t",
    "i",
    "o",
    "n",
    "s",
    " ",
    "f",
    "o",
    "r",
    " ",
    "e",
    "v",
    "a",
    "l",
    "u",
    "a",
    "t",
    "i",
    "o",
    "n",
    "\n",
    "h",
    "o",
    "n",
    "e",
    "s",
    "t",
    "_",
    "e",
    "v",
    "a",
    "l",
    "s",
    " ",
    "=",
    " ",
    "[",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "W",
    "h",
    "a",
    "t",
    " ",
    "a",
    "r",
    "e",
    " ",
    "t",
    "h",
    "e",
    " ",
    "t",
    "target",
    "p",
    "i",
    "c",
    "a",
    "l",
    " ",
    "c",
    "o",
    "v",
    "e",
    "r",
    "a",
    "g",
    "e",
    " ",
    "o",
    "p",
    "t",
    "i",
    "o",
    "n",
    "s",
    " ",
    "f",
    "o",
    "r",
    " ",
    "h",
    "o",
    "m",
    "e",
    "o",
    "w",
    "n",
    "e",
    "r",
    "s",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "W",
    "h",
    "a",
    "t",
    " ",
    "a",
    "r",
    "e",
    " ",
    "t",
    "h",
    "e",
    " ",
    "r",
    "e",
    "q",
    "u",
    "i",
    "r",
    "e",
    "m",
    "e",
    "n",
    "t",
    "s",
    " ",
    "f",
    "o",
    "r",
    " ",
    "l",
    "o",
    "n",
    "g",
    " ",
    "t",
    "e",
    "r",
    "m",
    " ",
    "c",
    "a",
    "r",
    "e",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    " ",
    "t",
    "o",
    " ",
    "s",
    "t",
    "a",
    "r",
    "t",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "C",
    "a",
    "n",
    " ",
    "a",
    "n",
    "n",
    "u",
    "i",
    "t",
    "target",
    " ",
    "b",
    "e",
    "n",
    "e",
    "f",
    "i",
    "t",
    "s",
    " ",
    "b",
    "e",
    " ",
    "p",
    "a",
    "s",
    "s",
    "e",
    "d",
    " ",
    "t",
    "o",
    " ",
    "b",
    "e",
    "n",
    "e",
    "f",
    "i",
    "c",
    "i",
    "a",
    "r",
    "i",
    "e",
    "s",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "A",
    "r",
    "e",
    " ",
    "c",
    "r",
    "e",
    "d",
    "i",
    "t",
    " ",
    "s",
    "c",
    "o",
    "r",
    "e",
    "s",
    " ",
    "u",
    "s",
    "e",
    "d",
    " ",
    "t",
    "o",
    " ",
    "s",
    "e",
    "t",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    " ",
    "p",
    "r",
    "e",
    "m",
    "i",
    "u",
    "m",
    "s",
    "?",
    " ",
    "I",
    "f",
    " ",
    "s",
    "o",
    ",",
    " ",
    "h",
    "o",
    "w",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "W",
    "h",
    "o",
    " ",
    "p",
    "r",
    "o",
    "v",
    "i",
    "d",
    "e",
    "s",
    " ",
    "f",
    "l",
    "o",
    "o",
    "d",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "C",
    "a",
    "n",
    " ",
    "target",
    "o",
    "u",
    " ",
    "g",
    "e",
    "t",
    " ",
    "f",
    "l",
    "o",
    "o",
    "d",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    " ",
    "o",
    "u",
    "t",
    "s",
    "i",
    "d",
    "e",
    " ",
    "h",
    "i",
    "g",
    "h",
    "-",
    "r",
    "i",
    "s",
    "k",
    " ",
    "a",
    "r",
    "e",
    "a",
    "s",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "H",
    "o",
    "w",
    " ",
    "m",
    "u",
    "c",
    "h",
    " ",
    "i",
    "n",
    " ",
    "l",
    "o",
    "s",
    "s",
    "e",
    "s",
    " ",
    "d",
    "o",
    "e",
    "s",
    " ",
    "f",
    "r",
    "a",
    "u",
    "d",
    " ",
    "a",
    "c",
    "c",
    "o",
    "u",
    "n",
    "t",
    " ",
    "f",
    "o",
    "r",
    " ",
    "i",
    "n",
    " ",
    "p",
    "r",
    "o",
    "p",
    "e",
    "r",
    "t",
    "target",
    " ",
    "&",
    " ",
    "c",
    "a",
    "s",
    "u",
    "a",
    "l",
    "t",
    "target",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "D",
    "o",
    " ",
    "p",
    "a",
    "target",
    "-",
    "a",
    "s",
    "-",
    "target",
    "o",
    "u",
    "-",
    "d",
    "r",
    "i",
    "v",
    "e",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "a",
    "n",
    "c",
    "e",
    " ",
    "p",
    "o",
    "l",
    "i",
    "c",
    "i",
    "e",
    "s",
    " ",
    "h",
    "a",
    "v",
    "e",
    " ",
    "a",
    "n",
    " ",
    "i",
    "m",
    "p",
    "a",
    "c",
    "t",
    " ",
    "o",
    "n",
    " ",
    "g",
    "r",
    "e",
    "e",
    "n",
    "h",
    "o",
    "u",
    "s",
    "e",
    " ",
    "g",
    "a",
    "s",
    " ",
    "e",
    "m",
    "i",
    "s",
    "s",
    "i",
    "o",
    "n",
    "s",
    "?",
    " ",
    "H",
    "o",
    "w",
    " ",
    "m",
    "u",
    "c",
    "h",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "W",
    "h",
    "a",
    "t",
    " ",
    "w",
    "a",
    "s",
    " ",
    "t",
    "h",
    "e",
    " ",
    "m",
    "o",
    "s",
    "t",
    " ",
    "c",
    "o",
    "s",
    "t",
    "l",
    "target",
    " ",
    "e",
    "a",
    "r",
    "t",
    "h",
    "q",
    "u",
    "a",
    "k",
    "e",
    " ",
    "i",
    "n",
    " ",
    "U",
    "S",
    " ",
    "h",
    "i",
    "s",
    "t",
    "o",
    "r",
    "target",
    " ",
    "f",
    "o",
    "r",
    " ",
    "i",
    "n",
    "s",
    "u",
    "r",
    "e",
    "r",
    "s",
    "?",
    "\"",
    ",",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "\"",
    "D",
    "o",
    "e",
    "s",
    " ",
    "i",
    "t",
    " ",
    "m",
    "a",
    "t",
    "t",
    "e",
    "r",
    " ",
    "w",
    "h",
    "o",
    " ",
    "i",
    "s",
    " ",
    "a",
    "t",
    " ",
    "f",
    "a",
    "u",
    "l",
    "t",
    " ",
    "t",
    "o",
    " ",
    "b",
    "e",
    " ",
    "c",
    "o",
    "m",
    "p",
    "e",
    "n",
    "s",
    "a",
    "t",
    "e",
    "d",
    " ",
    "w",
    "h",
    "e",
    "n",
    " ",
    "i",
    "n",
    "j",
    "u",
    "r",
    "e",
    "d",
    " ",
    "o",
    "n",
    " ",
    "t",
    "h",
    "e",
    " ",
    "j",
    "o",
    "b",
    "?",
    "\"",
    "\n",
    "]"
   ],
   "metadata": {},
   "cell_type": "code",
   "id": "b2d1577a-8476-4f6a-8702-4189d24dab67",
   "outputs": [],
   "execution_count": null
  },
  {
   "source": "## Set up Evaluation",
   "metadata": {},
   "id": "9da4f007-422c-45ca-a05c-f1e82288797f",
   "cell_type": "markdown"
  },
  {
   "source": [
    "import os",
    "import numptarget as np",
    "from trulens_eval import Tru, Feedback, TruLlama, OpenAI as fOpenAI",
    "",
    "from trulens_eval.feedback import Groundedness",
    "",
    "openai = fOpenAI()",
    "",
    "qa_relevance = (",
    "    Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")",
    "    .on_input_output()",
    ")",
    "",
    "qs_relevance = (",
    "    Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")",
    "    .on_input()",
    "    .on(TruLlama.select_source_nodes().node.text)",
    "    .aggregate(np.mean)",
    ")",
    "",
    "# embedding distance",
    "from langchain.embeddings.openai import OpenAIEmbeddings",
    "from trulens_eval.feedback import Embeddings",
    "",
    "model_name = 'text-embedding-ada-002'",
    "",
    "embed_model = OpenAIEmbeddings(",
    "    model=model_name,",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]",
    ")",
    "",
    "embed = Embeddings(embed_model=embed_model)",
    "f_embed_dist = (",
    "    Feedback(embed.cosine_distance)",
    "    .on_input()",
    "    .on(TruLlama.select_source_nodes().node.text)",
    ")",
    "",
    "from trulens_eval.feedback import Groundedness",
    "",
    "grounded = Groundedness(groundedness_provider=openai)",
    "",
    "f_groundedness = (",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")",
    "        .on(TruLlama.select_source_nodes().node.text.collect())",
    "        .on_output()",
    "        .aggregate(grounded.grounded_statements_aggregator)",
    ")",
    "",
    "honest_feedbacks = [qa_relevance, qs_relevance, f_embed_dist, f_groundedness]"
   ],
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 874,
    "lastExecutedAt": 1701189513508,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import os\nimport numpy as np\nfrom trulens_eval import Tru, Feedback, TruLlama, OpenAI as fOpenAI\n\nfrom trulens_eval.feedback import Groundedness\n\nopenai = fOpenAI()\n\nqa_relevance = (\n    Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n    .on_input_output()\n)\n\nqs_relevance = (\n    Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n    .on_input()\n    .on(TruLlama.select_source_nodes().node.text)\n    .aggregate(np.mean)\n)\n\n# embedding distance\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom trulens_eval.feedback import Embeddings\n\nmodel_name = 'text-embedding-ada-002'\n\nembed_model = OpenAIEmbeddings(\n    model=model_name,\n    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n)\n\nembed = Embeddings(embed_model=embed_model)\nf_embed_dist = (\n    Feedback(embed.cosine_distance)\n    .on_input()\n    .on(TruLlama.select_source_nodes().node.text)\n)\n\nfrom trulens_eval.feedback import Groundedness\n\ngrounded = Groundedness(groundedness_provider=openai)\n\nf_groundedness = (\n    Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n        .on(TruLlama.select_source_nodes().node.text.collect())\n        .on_output()\n        .aggregate(grounded.grounded_statements_aggregator)\n)\n\nhonest_feedbacks = [qa_relevance, qs_relevance, f_embed_dist, f_groundedness]",
    "outputsMetadata": {
     "0": {
      "height": 185,
      "type": "stream"
     }
    }
   },
   "id": "779812f4-daeb-45d0-a504-eefeb5bd7166",
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\nâœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\nâœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\nâœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\nâœ… In cosine_distance, input query will be set to __record__.main_input or `Select.RecordInput` .\nâœ… In cosine_distance, input document will be set to __record__.app.query.rets.source_nodes[:].node.text .\nâœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\nâœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
    }
   ]
  },
  {
   "source": "Our simple RAG often struggles with retrieving not enough information from the insurance manual to properly answer the question. The information needed may be just outside the chunk that is identified and retrieved by our app. Let's try sentence window retrieval to retrieve a wider chunk.",
   "metadata": {},
   "id": "7fd5d9b8-b5eb-4252-972c-b892fdcf1eb4",
   "cell_type": "markdown"
  },
  {
   "source": [
    "from llama_index.node_parser import SentenceWindowNodeParser",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank",
    "from llama_index import load_index_from_storage",
    "from llama_index import Document",
    "from llama_index import ServiceContext, VectorStoreIndex, StorageContext",
    "from llama_index.llms import OpenAI",
    "import os",
    "",
    "# initialize llm",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)",
    "",
    "# knowledge store",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))",
    "",
    "# set stargetstem prompt",
    "from llama_index import Prompt",
    "stargetstem_prompt = Prompt(\"We have provided context information below that targetou matarget use. \\n\"",
    "    \"---------------------\\n\"",
    "    \"{context_str}\"",
    "    \"\\n---------------------\\n\"",
    "    \"Please answer the question: {quertarget_str}\\n\")",
    "",
    "def build_sentence_window_index(",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"",
    "):",
    "    # create the sentence window node parser w/ default settings",
    "    node_parser = SentenceWindowNodeParser.from_defaults(",
    "        window_size=3,",
    "        window_metadata_key=\"window\",",
    "        original_text_metadata_key=\"original_text\",",
    "    )",
    "    sentence_context = ServiceContext.from_defaults(",
    "        llm=llm, # fill llm",
    "        embed_model=embed_model, # embed model",
    "        node_parser=node_parser, # node parser",
    "    )",
    "    if not os.path.exists(save_dir):",
    "        sentence_index = VectorStoreIndex.from_documents(",
    "            [document], service_context=sentence_context",
    "        )",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)",
    "    else:",
    "        sentence_index = load_index_from_storage(",
    "            StorageContext.from_defaults(persist_dir=save_dir),",
    "            service_context=sentence_context,",
    "        )",
    "",
    "    return sentence_index",
    "",
    "sentence_index = build_sentence_window_index(",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"",
    ")",
    "",
    "def get_sentence_window_quertarget_engine(",
    "    sentence_index,",
    "    stargetstem_prompt,",
    "    similarittarget_top_k=6, # top k",
    "    rerank_top_n=2,",
    "):",
    "    # define postprocessors",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")",
    "    rerank = SentenceTransformerRerank(",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"",
    "    )",
    "",
    "    sentence_window_engine = sentence_index.as_quertarget_engine(",
    "        similarittarget_top_k=similarittarget_top_k, node_postprocessors=[postproc, rerank], text_qa_template = stargetstem_prompt",
    "    )",
    "    return sentence_window_engine",
    "",
    "sentence_window_engine = get_sentence_window_quertarget_engine(sentence_index, stargetstem_prompt=stargetstem_prompt)",
    "",
    "tru_recorder_rag_sentencewindow = TruLlama(",
    "        sentence_window_engine,",
    "        app_id='2) Sentence Window RAG - Honest Eval',",
    "        feedbacks=honest_feedbacks",
    "    )"
   ],
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 18481,
    "lastExecutedAt": 1701189793026,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from llama_index.node_parser import SentenceWindowNodeParser\nfrom llama_index.indices.postprocessor import MetadataReplacementPostProcessor\nfrom llama_index.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index import load_index_from_storage\nfrom llama_index import Document\nfrom llama_index import ServiceContext, VectorStoreIndex, StorageContext\nfrom llama_index.llms import OpenAI\nimport os\n\n# initialize llm\nllm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n\n# knowledge store\ndocument = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n\n# set system prompt\nfrom llama_index import Prompt\nsystem_prompt = Prompt(\"We have provided context information below that you may use. \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"Please answer the question: {query_str}\\n\")\n\ndef build_sentence_window_index(\n    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n):\n    # create the sentence window node parser w/ default settings\n    node_parser = SentenceWindowNodeParser.from_defaults(\n        window_size=3,\n        window_metadata_key=\"window\",\n        original_text_metadata_key=\"original_text\",\n    )\n    sentence_context = ServiceContext.from_defaults(\n        llm=llm, # fill llm\n        embed_model=embed_model, # embed model\n        node_parser=node_parser, # node parser\n    )\n    if not os.path.exists(save_dir):\n        sentence_index = VectorStoreIndex.from_documents(\n            [document], service_context=sentence_context\n        )\n        sentence_index.storage_context.persist(persist_dir=save_dir)\n    else:\n        sentence_index = load_index_from_storage(\n            StorageContext.from_defaults(persist_dir=save_dir),\n            service_context=sentence_context,\n        )\n\n    return sentence_index\n\nsentence_index = build_sentence_window_index(\n    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n)\n\ndef get_sentence_window_query_engine(\n    sentence_index,\n    system_prompt,\n    similarity_top_k=6, # top k\n    rerank_top_n=2,\n):\n    # define postprocessors\n    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n    rerank = SentenceTransformerRerank(\n        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n    )\n\n    sentence_window_engine = sentence_index.as_query_engine(\n        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank], text_qa_template = system_prompt\n    )\n    return sentence_window_engine\n\nsentence_window_engine = get_sentence_window_query_engine(sentence_index, system_prompt=system_prompt)\n\ntru_recorder_rag_sentencewindow = TruLlama(\n        sentence_window_engine,\n        app_id='2) Sentence Window RAG - Honest Eval',\n        feedbacks=honest_feedbacks\n    )"
   },
   "id": "ac1ec265-82a3-4bce-a90d-841444dd3701",
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8002383484d54fe18d289c7ec6bc529c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8677f3372c2d42edaa0d6fc530671389"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52a384e244984a479fc402c5670a6e7c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f72ef5b66de4f52864361604069c39d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8c0decfba244b4697276d5097cfe392"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "source": [
    "#",
    " ",
    "R",
    "u",
    "n",
    " ",
    "e",
    "v",
    "a",
    "l",
    "u",
    "a",
    "t",
    "i",
    "o",
    "n",
    " ",
    "o",
    "n",
    " ",
    "1",
    "0",
    " ",
    "s",
    "a",
    "m",
    "p",
    "l",
    "e",
    " ",
    "q",
    "u",
    "e",
    "s",
    "t",
    "i",
    "o",
    "n",
    "s",
    "\n",
    "w",
    "i",
    "t",
    "h",
    " ",
    "t",
    "r",
    "u",
    "_",
    "r",
    "e",
    "c",
    "o",
    "r",
    "d",
    "e",
    "r",
    "_",
    "r",
    "a",
    "g",
    "_",
    "s",
    "e",
    "n",
    "t",
    "e",
    "n",
    "c",
    "e",
    "w",
    "i",
    "n",
    "d",
    "o",
    "w",
    " ",
    "a",
    "s",
    " ",
    "r",
    "e",
    "c",
    "o",
    "r",
    "d",
    "i",
    "n",
    "g",
    ":",
    "\n",
    " ",
    " ",
    " ",
    " ",
    "f",
    "o",
    "r",
    " ",
    "q",
    "u",
    "e",
    "s",
    "t",
    "i",
    "o",
    "n",
    " ",
    "i",
    "n",
    " ",
    "h",
    "o",
    "n",
    "e",
    "s",
    "t",
    "_",
    "e",
    "v",
    "a",
    "l",
    "s",
    ":",
    "\n",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    " ",
    "r",
    "e",
    "s",
    "p",
    "o",
    "n",
    "s",
    "e",
    " ",
    "=",
    " ",
    "s",
    "e",
    "n",
    "t",
    "e",
    "n",
    "c",
    "e",
    "_",
    "w",
    "i",
    "n",
    "d",
    "o",
    "w",
    "_",
    "e",
    "n",
    "g",
    "i",
    "n",
    "e",
    ".",
    "q",
    "u",
    "e",
    "r",
    "target",
    "(",
    "q",
    "u",
    "e",
    "s",
    "t",
    "i",
    "o",
    "n",
    ")"
   ],
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 54611,
    "lastExecutedAt": 1701189865007,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Run evaluation on 10 sample questions\nwith tru_recorder_rag_sentencewindow as recording:\n    for question in honest_evals:\n        response = sentence_window_engine.query(question)",
    "outputsMetadata": {
     "0": {
      "height": 437,
      "type": "stream"
     }
    }
   },
   "id": "e35774a4-a42d-4a73-a1da-ba46291b7382",
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
    }
   ]
  },
  {
   "source": [
    "t",
    "r",
    "u",
    ".",
    "g",
    "e",
    "t",
    "_",
    "l",
    "e",
    "a",
    "d",
    "e",
    "r",
    "b",
    "o",
    "a",
    "r",
    "d",
    "(",
    "a",
    "p",
    "p",
    "_",
    "i",
    "d",
    "s",
    "=",
    "[",
    "\"",
    "1",
    ")",
    " ",
    "B",
    "a",
    "s",
    "i",
    "c",
    " ",
    "R",
    "A",
    "G",
    " ",
    "-",
    " ",
    "H",
    "o",
    "n",
    "e",
    "s",
    "t",
    " ",
    "E",
    "v",
    "a",
    "l",
    "\"",
    ",",
    " ",
    "\"",
    "2",
    ")",
    " ",
    "S",
    "e",
    "n",
    "t",
    "e",
    "n",
    "c",
    "e",
    " ",
    "W",
    "i",
    "n",
    "d",
    "o",
    "w",
    " ",
    "R",
    "A",
    "G",
    " ",
    "-",
    " ",
    "H",
    "o",
    "n",
    "e",
    "s",
    "t",
    " ",
    "E",
    "v",
    "a",
    "l",
    "\"",
    "]",
    ")"
   ],
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 550,
      "type": "dataFrame",
      "tableState": {}
     }
    }
   },
   "id": "ab588e13-414a-456a-96b9-9321e5e16c13",
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "schema": {
         "fields": [
          {
           "name": "app_id",
           "type": "string"
          },
          {
           "name": "Answer Relevance",
           "type": "number"
          },
          {
           "name": "Groundedness",
           "type": "number"
          },
          {
           "name": "cosine_distance",
           "type": "number"
          },
          {
           "name": "Context Relevance",
           "type": "number"
          },
          {
           "name": "latency",
           "type": "number"
          },
          {
           "name": "total_cost",
           "type": "number"
          }
         ],
         "primaryKey": [
          "app_id"
         ],
         "pandas_version": "1.4.0"
        },
        "data": {
         "app_id": [
          "2) Sentence Window RAG - Honest Eval",
          "1) Basic RAG - Honest Eval"
         ],
         "Answer Relevance": [
          1,
          1
         ],
         "Groundedness": [
          1,
          0.4375
         ],
         "cosine_distance": [
          0.1362235936,
          0.1570688193
         ],
         "Context Relevance": [
          0.68,
          0.55
         ],
         "latency": [
          4.6,
          4.5
         ],
         "total_cost": [
          0.00071325,
          0.003316
         ]
        }
       },
       "total_rows": 2,
       "truncation_type": null
      },
      "text/plain": "                                      Answer Relevance  ...  total_cost\napp_id                                                  ...            \n2) Sentence Window RAG - Honest Eval               1.0  ...    0.000713\n1) Basic RAG - Honest Eval                         1.0  ...    0.003316\n\n[2 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer Relevance</th>\n      <th>Groundedness</th>\n      <th>cosine_distance</th>\n      <th>Context Relevance</th>\n      <th>latency</th>\n      <th>total_cost</th>\n    </tr>\n    <tr>\n      <th>app_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2) Sentence Window RAG - Honest Eval</th>\n      <td>1.0</td>\n      <td>1.0000</td>\n      <td>0.136224</td>\n      <td>0.68</td>\n      <td>4.6</td>\n      <td>0.000713</td>\n    </tr>\n    <tr>\n      <th>1) Basic RAG - Honest Eval</th>\n      <td>1.0</td>\n      <td>0.4375</td>\n      <td>0.157069</td>\n      <td>0.55</td>\n      <td>4.5</td>\n      <td>0.003316</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "source": "How does the sentence window RAG compare to our prototype? You decide!",
   "metadata": {},
   "id": "b7a0e72d-1fc1-4b43-a614-a1f771c232d5",
   "cell_type": "markdown"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "editor": "DataLab"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}