{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWUkRt7z2hkK"
   },
   "source": [
    "<h1> Experiment Tracking using MLFlow - Hrishikesh Dipak Desai</h1>\n",
    "\n",
    "---\n",
    "\n",
    "With 243M downloads and 14.8K stars on GitHub - MLflow is one of the most widely adopted open-source tools for machine learning lifecycle management. It supports live logging of parameters, metrics, and artifacts, in addition to providing a Model Registry with Deployment functionality.\n",
    "\n",
    "We integrated MLflow into DagsHub almost two years ago, providing a zero-configuration remote MLflow Server with built-in access controls, that support MLflow's Tracking, Model Registry, and Deployment functionality. We've dived into its internals, handled many of its specifics, and now we want to share the knowledge we gained with the data science community!\n",
    "\n",
    "\n",
    "1. **Intro to MLflow**Â - Learn what MLflow is and how it can help you manage your machine learning project.\n",
    "2. **Experiment Tracking**Â live logging of parameters, metrics, and artifacts as part of machine learning experiments.\n",
    "3. **Model Registry**Â - Log and manage your machine learning models with MLflow.\n",
    "2. **Model Deployment** -Â Deploy your trained model from the MLflow registry to AWS.\n",
    "\n",
    "\n",
    "---\n",
    "<h4>\n",
    "In the project today, we will use DagsHub integration with MLflow. â¤ï¸\n",
    "\n",
    "You will log experiment to a remote server by running only 3 simple commands!\n",
    "\n",
    "</h4>\n",
    "\n",
    "\n",
    "[Discord Channel](https://discord.com/channels/698874030052212737/698874030572437526) |  [LinkedIn](https://www.linkedin.com/company/dagshub/) |  [Twitter](https://twitter.com/TheRealDAGsHub) | [GitHub](https://github.com/DAGsHub) | [MLFlow](https://www.mlflow.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5AX2fpblSyP"
   },
   "source": [
    "# â“ What are we learning today?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG6_hUNcE4qy"
   },
   "source": [
    "- Why do we need MLflow?\n",
    "- What is MLflow?\n",
    "- MLflow Tracking Functionality\n",
    "  - Understanding Runs & Experiments\n",
    "  - Logging Runs & Experiments\n",
    "  - How and where are the runs recorded?\n",
    "- Hands-on Experience using MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5e-om3x4qeA"
   },
   "source": [
    "\n",
    "# ğŸ¤Œ Why do we need MLFlow?\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"https://drive.google.com/uc?id=1ZMVUUsVDRaGRD_aIa8E-4lkGFxxo1WGB\" height=\"200\" />\n",
    "  <img src=\"https://drive.google.com/uc?id=1tK9igz88eMHV115R_0jDuzuPBY9GSTRQ\" height=\"220\" />\n",
    "  <img src=\"https://drive.google.com/uc?id=11QSKrW29sWfD2lPse_hXpYD9Ql6tLQjo\" height=\"200\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtInWfJ_zZ0B"
   },
   "source": [
    "\n",
    "**<h3>ğŸ’¡The effort and time spent in logging the experiments is always underestimated</h3>**\n",
    "\n",
    "Do you find yourself doing CTRL-Y / â‡§âŒ˜Z multiple times to find that perfect code which gave you an awesome accuracy or confidence score before you messed it up with the new experiment you decided to run? Or the optimal set of hyper parameters that you used for that run?\n",
    "\n",
    "**<h3>â“Another question that arises is of reproducibility of your experiments.</h3>**\n",
    "\n",
    "A colleague of mine structured their experiments using a Notion Table to keep track of them :\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1xD1aR3-yZICt9vMIdIHkATBMBAS6Pcbx\" height=\"\"/>\n",
    "</center>\n",
    "\n",
    "\n",
    "While Notion is a great tool for note keeping, we canâ€™t say the same when it comes to tracking the machine learning experimentation and workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyObzxJLjGJm"
   },
   "source": [
    "# âš¡ What is MLFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIU_pHsS5LDz"
   },
   "source": [
    "\n",
    "\n",
    "MLflow is an **open-source tool** to manage the machine learning lifecycle. It supports **live logging** of parameters, metrics, metadata, and artifacts when running a machine learning experiment. To manage the post-training stage, it provides a **model registry** with **deployment functionality** to custom serving tools.\n",
    "\n",
    "It was created to :\n",
    "- Reduce the complexity in monitoring the experiments.\n",
    "- Ease the reproducibility of theÂ results.\n",
    "- Cater the need of a standardized mechanism to register and deploy models to production.\n",
    "\n",
    "**<h3> ğŸ‚ Introduced in June 2018 by Databricks to offer </h3>**\n",
    "- **Open interface** : Any ML library, algorithm, cloud provider, or language may be used with MLflow.\n",
    "- **Open source** :Â MLflow is anÂ open source projectÂ that users and library developers can extend.\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1m0uXc3gZff1prgl_-DRfmg5whRwWboFJ\" height=\"\"/>\n",
    "</center>\n",
    "\n",
    "Reference blog to the stats - Click [here](https://www.databricks.com/blog/2018/06/05/introducing-mlflow-an-open-source-machine-learning-platform.html)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHfth5VnAYr0"
   },
   "source": [
    "### ğŸ§© The MLFlow Components:\n",
    "\n",
    "**Components that MLFlow offers to help you manage your workflow :**\n",
    "1. **MLflow Tracking -** Log parameters, metrics, and artifacts when running a machine learning code.\n",
    "2. **MLflow Projects**Â - Package and reuse data science code.\n",
    "3. **MLflow Registry -** Manage the lifespan of ML Model.\n",
    "4. **MLflow Models**Â - Package and deploy ML models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft1TaiLVCIzO"
   },
   "source": [
    "# ğŸ”¥MLflow Tracking Functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSePjmf5F8Jz"
   },
   "source": [
    "## ğŸƒâ€â™‚ï¸& ğŸ§ª Understanding Runs & Experiments\n",
    "\n",
    "- The **experiment** unit in MLflow can be handled as a \"project\" or as a \"approach\".  \n",
    "- The term **run** merely refers to a run or execution of a code once.\n",
    "\n",
    "*More than one run might be associated with a single experiment.*\n",
    "\n",
    "Each run is an execution of your data science code which records the following:\n",
    "\n",
    "- **Source of execution**: Contains the hash of the commit if the code was pushed to GitHub and the original line of code that was utilized for the run.\n",
    "- **Artifacts**: Artifacts are output files recorded during a run.\n",
    "- **Parameters**: Parameters are stored in the key-value format.\n",
    "- **Metrics:** The evaluation metrics such as RMSE or ROC-AUC are recorded in a run as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNOfQVFOju3Q"
   },
   "source": [
    "## âœï¸ How and where are the runs recorded?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZrJPCBjCIvw"
   },
   "source": [
    "*Runs of MLflow can be stored locally in files, remotely on a tracking server, or in a database that is compatible with [SQLAlchemy](https://www.sqlalchemy.org/) - an open-source SQL toolkit and object-relational mapper for the Python programming language.*\n",
    "\n",
    "### Scenario 1: MLflow on localhost\n",
    "- A good first-time technique to get started.\n",
    "- MLflow will create a directory called **./mlruns** on your local system as soon as you import MLflow and log an artifact.\n",
    "- Limitations on collaboration because experiments or results can't be shared with a team.\n",
    "- Tracking UI - To visualize, search and compare runs, as well as download run artifacts or metadata for analysis in other tools by running the command `mlflow ui`.\n",
    "<center> <img src=\"https://drive.google.com/uc?id=182URyB-0ezmZCkQg-TKVrt-OmYbiyECM\" height=\"150%\"/>\n",
    "</center>\n",
    "\n",
    "The UI contains the following key features:\n",
    "\n",
    "- Experiment-based run listing and comparison (including run comparison across multiple experiments)\n",
    "- Searching for runs by parameter or metric value\n",
    "- Visualizing run metrics\n",
    "- Downloading run results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhgxn4RSj4kk"
   },
   "source": [
    "### Scenario 2: MLflow on localhost with SQLite\n",
    "\n",
    "The only difference between this process and the previous one is that we use a local database such as SQLite instead of storing runs to files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IoeEu-Mj4bC"
   },
   "source": [
    "\\\\\n",
    "\n",
    "### Scenario 3: MLflow on localhost with Tracking Server\n",
    "\n",
    "This scenario is again similar to the first scenario but here, you can setup a remote server using `mlflow server <args>` which will launch the tracking server at the default port 5000.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO6gTnOrj4X2"
   },
   "source": [
    "### Scenario 4: MLflow with remote Tracking Server, backend and artifact stores\n",
    "- The tracking server, backend store, and artifact store may all be located on different hosts in distributed architectures.\n",
    "- The MLflow client communicates with the tracking server through a sequence of REST requests in order to record all runs' MLflow entities.\n",
    "- The MLflow client interacts with the remote Tracking Server and artifact storage host such as AWS using theÂ boto clientÂ libraries, and uploads the artifacts to the S3 bucket URI location.\n",
    "- This set up requires DevOps knowledge.\n",
    "\n",
    "\\\\\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1iqhhqw7yT4GjUlpV6IoYLLuy1BeVtDA0\" height=\"120%\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC2FkQoOj4V-"
   },
   "source": [
    "### Scenario 5: MLflow Tracking Server enabled with proxied artifact storage access\n",
    "\n",
    "\\\\\n",
    "\n",
    "*In this case, it is not necessary to grant end users direct path access to a remote object store (such as S3, ADL, GCS, or HDFS) for the management of artifact, nor is it necessary for an end user to provide access credentials.*\n",
    "\n",
    "\\\\\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=17ERqAUwx7OUcph3EjPUPL4OoyCwuhh2W\" height=\"120%\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ou-zNZOZp2n"
   },
   "source": [
    "### Scenario 6: MLflow x DagsHub\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1kDoJcbYj_mebQ-6Dh6aPe-OE5LNSvqsR\" height=\"80%\"/>\n",
    "</center>\n",
    "\n",
    "- Going through all the above can be a bit of an hassle, even for people with DevOps background. To simplify the process, DagsHub decided to do the MLOps heavy lifting.\n",
    "\n",
    "- **DagsHub provides a free remote MLflow server with every repository.**\n",
    "\n",
    "- You can log experiments with MLflow to it, view its information under theÂ [experiment tab](https://dagshub.com/docs/feature_guide/discovering_experiments/), and manage your trained models from the full-fledged MLflow UI built into your DagsHub project.\n",
    "\n",
    "- When you create a repository on DagsHub, a remote MLflow server is automatically created and configured with the project. The repository's MLflow tracking server will be located at:\n",
    "\n",
    "  `https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow`\n",
    "\n",
    "<center><h3>In the project today, we will use DagsHub integration with MLflow and log experiment to a remote server by running only 3 simple commands!</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfujaAmeGeHH"
   },
   "source": [
    "# ğŸ’» Hands-on Experience using MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sBsk3NOGhJG"
   },
   "source": [
    "To demo the MLflow functionality, I chose to use [Eryk Lewinson's awesome project](https://dagshub.com/eryk.lewinson/mario_vs_wario_v2), where he trains a neural network to classify images as containing Mario or Wario.\n",
    "\n",
    "To shorten the training time, I created a fork that trimmed the pipeline and uses a subset of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E4MGW5-FTE-"
   },
   "source": [
    "## ğŸ‘·â€â™€ï¸ Setup the project in Colab Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl78R8dPkRbD"
   },
   "source": [
    "### DagsHub Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg-Q1mtJF0bf"
   },
   "source": [
    "**First: fork the [base repository](https://dagshub.com/DagsHub/mario_vs_wario) to your account!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sj71-Rf80xAw"
   },
   "outputs": [],
   "source": [
    "!pip install dagshub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYf_kSRufbIP"
   },
   "outputs": [],
   "source": [
    "#@markdown Enter the username of your DagsHub account:\n",
    "DAGSHUB_USER_NAME = \"hddesai1\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the email for your DagsHub account:\n",
    "DAGSHUB_EMAIL = \"hrishikeshdesai05@gmail.com\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the name of the forked repository!\n",
    "DAGSHUB_REPO = \"mario_vs_wario\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugEEh97mPfCy"
   },
   "source": [
    " **Generate an OAuth Token, for improved account security**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilUliyVH0qym"
   },
   "outputs": [],
   "source": [
    "import dagshub\n",
    "import os\n",
    "\n",
    "DAGSHUB_TOKEN = dagshub.auth.get_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU7dNou0F9m_"
   },
   "source": [
    "## â¬ Clone the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQsYUtDwGE1w"
   },
   "source": [
    "**Configure Git**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkYJ39OXF7WK"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email {DAGSHUB_EMAIL}\n",
    "!git config --global user.name {DAGSHUB_USER_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd02jjRRGGFu"
   },
   "source": [
    "**Clone the Repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Og48wUBwGASF",
    "outputId": "f4f60f64-1a6a-4904-d2b6-79f99882dfad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "fatal: destination path 'mario_vs_wario' already exists and is not an empty directory.\n",
      "/content/mario_vs_wario\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!git clone https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO}.git\n",
    "%cd {DAGSHUB_REPO}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5DIqa7EGqsz"
   },
   "source": [
    "## â³ Install MLflow\n",
    "MLflow is installed using pip.\n",
    "\n",
    "*Note*: MLflow has two variants, each with different support.\n",
    "\n",
    "* Install MLflow\n",
    "\n",
    "  `pip install mlflow`\n",
    "\n",
    "* Install a lightweight version of MLflow\n",
    "    \n",
    "    `pip install mlflow-skinny`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3grGRw_ZGn1B"
   },
   "outputs": [],
   "source": [
    "!pip install mlflow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPDpKEKKaYvN"
   },
   "source": [
    "### ğŸ Getting Started\n",
    "\n",
    "Let's dive into this project by exploring the [data pipeline](https://dagshub.com/DagsHub/mario_vs_wario)!\n",
    "\n",
    "From there, we can see that `src/train.py` is a pivotal script. Let's watch it work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "XRwtuORn3oFo",
    "outputId": "77e3e6b4-e2ee-4fc2-9081-367134b25e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dvc\n",
      "  Downloading dvc-3.59.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from dvc) (25.1.0)\n",
      "Collecting celery (from dvc)\n",
      "  Downloading celery-5.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting colorama>=0.3.9 (from dvc)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting configobj>=5.0.9 (from dvc)\n",
      "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: distro>=1.3 in /usr/local/lib/python3.11/dist-packages (from dvc) (1.9.0)\n",
      "Collecting dpath<3,>=2.1.0 (from dvc)\n",
      "  Downloading dpath-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting dulwich (from dvc)\n",
      "  Downloading dulwich-0.22.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting dvc-data<3.17,>=3.16.2 (from dvc)\n",
      "  Downloading dvc_data-3.16.9-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting dvc-http>=2.29.0 (from dvc)\n",
      "  Downloading dvc_http-2.32.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting dvc-objects (from dvc)\n",
      "  Downloading dvc_objects-5.1.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting dvc-render<2,>=1.0.1 (from dvc)\n",
      "  Downloading dvc_render-1.0.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dvc-studio-client<1,>=0.21 (from dvc)\n",
      "  Downloading dvc_studio_client-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting dvc-task<1,>=0.3.0 (from dvc)\n",
      "  Downloading dvc_task-0.40.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting flatten_dict<1,>=0.4.1 (from dvc)\n",
      "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting flufl.lock<9,>=8.1.0 (from dvc)\n",
      "  Downloading flufl_lock-8.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: fsspec>=2024.2.0 in /usr/local/lib/python3.11/dist-packages (from dvc) (2024.10.0)\n",
      "Collecting funcy>=1.14 (from dvc)\n",
      "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting grandalf<1,>=0.7 (from dvc)\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting gto<2,>=1.6.0 (from dvc)\n",
      "  Downloading gto-1.7.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting hydra-core>=1.1 (from dvc)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting iterative-telemetry>=0.0.7 (from dvc)\n",
      "  Downloading iterative_telemetry-0.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting kombu (from dvc)\n",
      "  Downloading kombu-5.4.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from dvc) (3.4.2)\n",
      "Collecting omegaconf (from dvc)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: packaging>=19 in /usr/local/lib/python3.11/dist-packages (from dvc) (24.2)\n",
      "Collecting pathspec>=0.10.3 (from dvc)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from dvc) (4.3.6)\n",
      "Requirement already satisfied: psutil>=5.8 in /usr/local/lib/python3.11/dist-packages (from dvc) (5.9.5)\n",
      "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from dvc) (3.0.4)\n",
      "Collecting pygtrie>=2.3.2 (from dvc)\n",
      "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.11/dist-packages (from dvc) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.11/dist-packages (from dvc) (2.32.3)\n",
      "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.11/dist-packages (from dvc) (13.9.4)\n",
      "Collecting ruamel.yaml>=0.17.11 (from dvc)\n",
      "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting scmrepo<4,>=3.3.8 (from dvc)\n",
      "  Downloading scmrepo-3.3.10-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting shortuuid>=0.5 (from dvc)\n",
      "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting shtab<2,>=1.3.4 (from dvc)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.11/dist-packages (from dvc) (0.9.0)\n",
      "Collecting tomlkit>=0.11.1 (from dvc)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.63.1 in /usr/local/lib/python3.11/dist-packages (from dvc) (4.67.1)\n",
      "Collecting voluptuous>=0.11.7 (from dvc)\n",
      "  Downloading voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting zc.lockfile>=1.2.1 (from dvc)\n",
      "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting dictdiffer>=0.8.1 (from dvc-data<3.17,>=3.16.2->dvc)\n",
      "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting diskcache>=5.2.1 (from dvc-data<3.17,>=3.16.2->dvc)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sqltrie<1,>=0.11.0 (from dvc-data<3.17,>=3.16.2->dvc)\n",
      "  Downloading sqltrie-0.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: orjson<4,>=3 in /usr/local/lib/python3.11/dist-packages (from dvc-data<3.17,>=3.16.2->dvc) (3.10.15)\n",
      "Collecting aiohttp-retry>=2.5.0 (from dvc-http>=2.29.0->dvc)\n",
      "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting billiard<5.0,>=4.2.0 (from celery->dvc)\n",
      "  Downloading billiard-4.2.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting vine<6.0,>=5.1.0 (from celery->dvc)\n",
      "  Downloading vine-5.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: click<9.0,>=8.1.2 in /usr/local/lib/python3.11/dist-packages (from celery->dvc) (8.1.8)\n",
      "Collecting click-didyoumean>=0.3.0 (from celery->dvc)\n",
      "  Downloading click_didyoumean-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting click-repl>=0.2.0 (from celery->dvc)\n",
      "  Downloading click_repl-0.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting click-plugins>=1.1.1 (from celery->dvc)\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from celery->dvc) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from celery->dvc) (2.8.2)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in /usr/local/lib/python3.11/dist-packages (from flatten_dict<1,>=0.4.1->dvc) (1.17.0)\n",
      "Requirement already satisfied: atpublic in /usr/local/lib/python3.11/dist-packages (from flufl.lock<9,>=8.1.0->dvc) (4.1.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from gto<2,>=1.6.0->dvc) (0.4)\n",
      "Requirement already satisfied: pydantic!=2.0.0,<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from gto<2,>=1.6.0->dvc) (2.10.6)\n",
      "Requirement already satisfied: semver>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from gto<2,>=1.6.0->dvc) (3.0.4)\n",
      "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gto<2,>=1.6.0->dvc) (0.15.2)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->dvc)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from iterative-telemetry>=0.0.7->dvc) (1.4.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from iterative-telemetry>=0.0.7->dvc) (3.17.0)\n",
      "Collecting amqp<6.0.0,>=5.1.1 (from kombu->dvc)\n",
      "  Downloading amqp-5.3.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf->dvc) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->dvc) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->dvc) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->dvc) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->dvc) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->dvc) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->dvc) (2.18.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.11->dvc)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: gitpython>3 in /usr/local/lib/python3.11/dist-packages (from scmrepo<4,>=3.3.8->dvc) (3.1.44)\n",
      "Requirement already satisfied: pygit2>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from scmrepo<4,>=3.3.8->dvc) (1.17.0)\n",
      "Collecting asyncssh<3,>=2.13.1 (from scmrepo<4,>=3.3.8->dvc)\n",
      "  Downloading asyncssh-2.20.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zc.lockfile>=1.2.1->dvc) (75.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (3.11.13)\n",
      "Requirement already satisfied: cryptography>=39.0 in /usr/local/lib/python3.11/dist-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.3.8->dvc) (43.0.3)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.3.8->dvc) (4.12.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in /usr/local/lib/python3.11/dist-packages (from click-repl>=0.2.0->celery->dvc) (3.0.50)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>3->scmrepo<4,>=3.3.8->dvc) (4.0.12)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12->dvc) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc) (2.27.2)\n",
      "Requirement already satisfied: cffi>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from pygit2>=1.14.0->scmrepo<4,>=3.3.8->dvc) (1.17.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.4.1->gto<2,>=1.6.0->dvc) (1.5.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.18.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.17.0->pygit2>=1.14.0->scmrepo<4,>=3.3.8->dvc) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<4,>=3.3.8->dvc) (5.0.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc) (0.2.13)\n",
      "Downloading dvc-3.59.1-py3-none-any.whl (457 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m457.7/457.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
      "Downloading dpath-2.2.0-py3-none-any.whl (17 kB)\n",
      "Downloading dvc_data-3.16.9-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.2/77.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dvc_http-2.32.0-py3-none-any.whl (12 kB)\n",
      "Downloading dvc_objects-5.1.0-py3-none-any.whl (33 kB)\n",
      "Downloading dvc_render-1.0.2-py3-none-any.whl (22 kB)\n",
      "Downloading dvc_studio_client-0.21.0-py3-none-any.whl (16 kB)\n",
      "Downloading dvc_task-0.40.2-py3-none-any.whl (21 kB)\n",
      "Downloading celery-5.4.0-py3-none-any.whl (425 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m426.0/426.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
      "Downloading flufl_lock-8.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gto-1.7.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading iterative_telemetry-0.0.10-py3-none-any.whl (10 kB)\n",
      "Downloading kombu-5.4.2-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading vine-5.1.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scmrepo-3.3.10-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dulwich-0.22.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
      "Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
      "Downloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Downloading amqp-5.3.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asyncssh-2.20.0-py3-none-any.whl (373 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading billiard-4.2.1-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click_didyoumean-0.3.1-py3-none-any.whl (3.6 kB)\n",
      "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading click_repl-0.3.0-py3-none-any.whl (10 kB)\n",
      "Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqltrie-0.11.2-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=2558a22a9b2cfc2daa5446cf856b55825dff4962e67ecce70044125428fb5564\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: pygtrie, funcy, dictdiffer, antlr4-python3-runtime, zc.lockfile, voluptuous, vine, tomlkit, sqltrie, shtab, shortuuid, ruamel.yaml.clib, pathspec, omegaconf, grandalf, flufl.lock, flatten_dict, dvc-render, dvc-objects, dulwich, dpath, diskcache, configobj, colorama, click-plugins, click-didyoumean, billiard, ruamel.yaml, iterative-telemetry, hydra-core, dvc-studio-client, dvc-data, click-repl, amqp, kombu, asyncssh, aiohttp-retry, scmrepo, dvc-http, celery, gto, dvc-task, dvc\n",
      "Successfully installed aiohttp-retry-2.9.1 amqp-5.3.1 antlr4-python3-runtime-4.9.3 asyncssh-2.20.0 billiard-4.2.1 celery-5.4.0 click-didyoumean-0.3.1 click-plugins-1.1.1 click-repl-0.3.0 colorama-0.4.6 configobj-5.0.9 dictdiffer-0.9.0 diskcache-5.6.3 dpath-2.2.0 dulwich-0.22.8 dvc-3.59.1 dvc-data-3.16.9 dvc-http-2.32.0 dvc-objects-5.1.0 dvc-render-1.0.2 dvc-studio-client-0.21.0 dvc-task-0.40.2 flatten_dict-0.4.2 flufl.lock-8.1.0 funcy-2.0 grandalf-0.8 gto-1.7.2 hydra-core-1.3.2 iterative-telemetry-0.0.10 kombu-5.4.2 omegaconf-2.3.0 pathspec-0.12.1 pygtrie-2.5.0 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 scmrepo-3.3.10 shortuuid-1.0.13 shtab-1.7.1 sqltrie-0.11.2 tomlkit-0.13.2 vine-5.1.0 voluptuous-0.15.2 zc.lockfile-3.0.post1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "3ad14f1d516448e49ec3455fd93f6b71",
       "pip_warning": {
        "packages": [
         "pydevd_plugins"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "CkDL7Pss3OvX",
    "outputId": "ed217469-501d-4175-f5fb-7328cf41d575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting          |192 [00:01,  156entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "Querying remote cache:   0% 0/2 [00:00<?, ?files/s]\u001b[A\n",
      "Querying remote cache:   0% 0/2 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
      "Querying remote cache:  50% 1/2 [00:00<00:00,  6.93files/s{'info': ''}]\u001b[A\n",
      "                                                                       \u001b[A\n",
      "Fetching from https:   0% 0/185 [00:00<?, ?file/s]\u001b[A\n",
      "Fetching from https:   0% 0/185 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
      "Fetching from https:   0% 0/4 [00:00<?, ?file/s{'info': ''}]  \u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  25% 1/4 [00:00<00:00,  6.30file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  50% 2/4 [00:00<00:00,  7.16file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "          |5.10M [00:00,    53.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "          |8.82M [00:00,    44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                     \u001b[A\u001b[A\n",
      "Fetching from https: 100% 4/4 [00:00<00:00,  7.30file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "  0%|          |Fetching from https               5/? [00:00<00:00,  6.65file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:   3% 6/179 [00:01<00:38,  4.51file/s{'info': ''}]          \u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:   4% 7/179 [00:01<00:34,  5.02file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:   8% 15/179 [00:01<00:10, 16.38file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  11% 20/179 [00:01<00:07, 21.74file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  13% 24/179 [00:01<00:06, 23.40file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "!\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                    \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  17% 30/179 [00:01<00:04, 30.03file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  19% 34/179 [00:02<00:04, 31.62file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  21% 38/179 [00:02<00:04, 32.64file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  23% 42/179 [00:02<00:03, 34.36file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  26% 46/179 [00:02<00:03, 35.56file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  28% 50/179 [00:02<00:03, 36.38file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  30% 54/179 [00:02<00:03, 35.44file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  32% 58/179 [00:02<00:03, 33.60file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  35% 63/179 [00:02<00:03, 37.42file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  37% 67/179 [00:03<00:03, 35.52file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  41% 74/179 [00:03<00:02, 35.36file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  44% 79/179 [00:03<00:02, 35.84file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  47% 84/179 [00:03<00:02, 38.46file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  50% 89/179 [00:03<00:02, 39.48file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  53% 94/179 [00:03<00:02, 35.17file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  55% 98/179 [00:03<00:02, 34.95file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  58% 104/179 [00:03<00:01, 39.67file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  61% 109/179 [00:04<00:01, 39.67file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  64% 114/179 [00:04<00:01, 35.45file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  66% 119/179 [00:04<00:01, 35.32file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  70% 125/179 [00:04<00:01, 37.88file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  72% 129/179 [00:04<00:01, 38.14file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  75% 134/179 [00:04<00:01, 40.33file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  78% 139/179 [00:04<00:01, 39.92file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  80% 144/179 [00:05<00:00, 38.79file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  83% 148/179 [00:05<00:00, 38.98file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  85% 153/179 [00:05<00:00, 36.51file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  88% 158/179 [00:05<00:00, 39.72file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  91% 163/179 [00:05<00:00, 36.99file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  94% 169/179 [00:05<00:00, 39.01file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https:  97% 174/179 [00:05<00:00, 41.43file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching from https: 100% 179/179 [00:05<00:00, 35.46file/s{'info': ''}]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "  0%|          |Fetching from https             184/? [00:06<00:00, 35.56file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "          |0.00 [00:00,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                    \u001b[A\u001b[A\n",
      "Fetching\n",
      "Building workspace index          |0.00 [00:00,    ?entry/s]\n",
      "Comparing indexes          |193 [00:00, 2.26kentry/s]\n",
      "Applying changes          |183 [00:00, 2.70kfile/s] \n",
      "\u001b[32mA\u001b[0m       models/\n",
      "\u001b[32mA\u001b[0m       data/\n",
      "2 files added and 185 files fetched\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9zotxrG5xRB",
    "outputId": "c729e449-1284-4b05-eec2-6fbc48d767bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 images belonging to 2 classes.\n",
      "Found 25 images belonging to 2 classes.\n",
      "Found 45 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025/03/12 01:48:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.5253 - loss: 0.7327 - val_accuracy: 0.4400 - val_loss: 0.6972\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 501ms/step - accuracy: 0.6647 - loss: 0.6556 - val_accuracy: 0.6000 - val_loss: 0.6725\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672ms/step - accuracy: 0.5704 - loss: 0.6657 - val_accuracy: 0.6000 - val_loss: 0.6573\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 509ms/step - accuracy: 0.5834 - loss: 0.6450 - val_accuracy: 0.6000 - val_loss: 0.6455\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 846ms/step - accuracy: 0.6730 - loss: 0.6543 - val_accuracy: 0.8400 - val_loss: 0.6371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 01:48:49 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: API request to endpoint /api/2.0/mlflow/runs/create failed with error code 403 != 200. Response body: ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Evaluating the model...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6736 - loss: 0.6446\n",
      "Evaluating completed.\n",
      "Saving the model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%run src/training_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFuhDoUQ3-1-",
    "outputId": "85ae43c3-a49d-4668-abc0-41d56ad35121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0M\tdata\n"
     ]
    }
   ],
   "source": [
    "!du -sh dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-anNKKYaGxuv"
   },
   "source": [
    "##  Log Experiments Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1vQ19POG30n"
   },
   "source": [
    "#### 1. Import MLflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6QZf0cpOE4q"
   },
   "source": [
    "```\n",
    "# We will import mlflow to the train.py where we will later log our runs.\n",
    "import mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzE99ovrHF1t"
   },
   "source": [
    "#### 2. Create an Experiment & Get the Experiment ID\n",
    "\n",
    "There are two ways to create an experiment with MLflow :\n",
    "1. **CLI** (Command-Line Interface)\n",
    "\n",
    "  MLflow supports various functionalities from the [CLI](https://www.mlflow.org/docs/latest/cli.html). You can use the CLI to run projects, launch the Tracking UI, create and list experiments, and more.\n",
    "\n",
    "  To create a new experiment use:\n",
    "  ```\n",
    "  mlflow experiments create --experiment-name <experiment_name>\n",
    "  ```\n",
    "\n",
    "2. **Python API**\n",
    "    ```\n",
    "    mlflow.create_experiment(name)\n",
    "    ```\n",
    "\n",
    "**Note**: The process of creating an experiment should be separated from the project pipeline or main code because we don't need to create a new one every time we run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUrFUDJZY7m-"
   },
   "source": [
    "```\n",
    "\n",
    "import mlflow\n",
    "\n",
    "def get_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "      exp_id = mlflow.create_experiment(name)\n",
    "      return exp_id\n",
    "    return exp.experiment_id\n",
    "\n",
    "print(get_experiment_id(\"mario_wario\"))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXbaGC5CGtP4",
    "outputId": "59e0503b-4175-4dae-c810-2b6032447e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277655743075825998\n"
     ]
    }
   ],
   "source": [
    "%run src/get_or_create_mlflow_experiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUeAdt1TI_5W"
   },
   "source": [
    "#### 3. Allocate the run to the Experiment\n",
    "\n",
    "We start an MLflow run with the command :\n",
    "```\n",
    "with mlflow.start_run(experiment_id=<experiment id>):\n",
    "```\n",
    "We will copy paste this to our train.py with the Experiment ID that we obtained from our last code execution.\n",
    "\n",
    "***Note:*** The code that followes this line needs to be indented to the `with` block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q_aHvrnIlv1"
   },
   "source": [
    "#### 4. Log Information  \n",
    "\n",
    "We will start by importing MLflow into our notebook or a .py file. Then we can start using the manual logging commands to log parameters, metrics, artifacts, and general using the following methods:\n",
    "\n",
    "* **Parameters**:\n",
    "  * [Single parameter](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param): mlflow.log_param(*key, value*)\n",
    "  * [Multiple parameters](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_params): mlflow.log_params(*dict*)\n",
    "* **Metrics:**\n",
    "  * [Single metric](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric): mlflow.log_metric(*key, value*)\n",
    "  * [Multiple metrics](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metrics): mlflow.log_metrics(*dict*)\n",
    "* **Artifacts**:\n",
    "  * [Single artifact](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact): mlflow.log_artifact(*local_path: str*)\n",
    "* **Text**:\n",
    "  * [Text](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_text): mlflow.log_text(*string*,*local_path: str*)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "***Note***: MLflow has additional logging capabilities, to read more about them please refer to the [MLflow Tracking docs](https://www.mlflow.org/docs/latest/python_api/mlflow.html#module-mlflow)\n",
    "\n",
    "\n",
    "***Note***: All the mlflow code in this section should be under the `with mlflow.start_run(experiment_id=<experiment id>):` line from the previous section.\n",
    "\n",
    "```\n",
    "# Single parameter\n",
    "mlflow.log_param(\"img_size\", IMG_SIZE)\n",
    "\n",
    "# Multiple parameters\n",
    "mlflow.log_params({\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"learning_rate\": LR,\n",
    "    \"epochs\": EPOCHS\n",
    "})\n",
    "\n",
    "# Single metric\n",
    "mlflow.log_metric(\"test_set_loss\", test_loss, step=1)\n",
    "\n",
    "\n",
    "# Multiple metrics\n",
    "mlflow.log_metrics(\n",
    "    {\n",
    "        \"test_set_loss\": test_loss,\n",
    "        \"test_set_accuracy\": test_accuracy,\n",
    "    }\n",
    ")\n",
    "\n",
    "mlflow.log_artifact(MODELS_DIR)\n",
    "\n",
    "mlflow.log_text(\"Here you can add general inforamtion about the run\",\"run_info.txt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fuui_bvgKmaP"
   },
   "source": [
    "#### 5. Time to see the magic! ğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CwOvl5myQF4"
   },
   "outputs": [],
   "source": [
    "!git checkout HEAD -- src/training_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftxNUfLkzZdQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "w4F11GuVIWIq",
    "outputId": "0bb9d312-fb77-4da9-a385-5a60cbcc37cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 images belonging to 2 classes.\n",
      "Found 25 images belonging to 2 classes.\n",
      "Found 45 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 03:52:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b5f84733a56e4e878c9796dc58dc853e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 03:52:10 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "2025/03/12 03:52:10 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - accuracy: 0.5593 - loss: 0.7299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703ms/step - accuracy: 0.5578 - loss: 0.7383 - val_accuracy: 0.6000 - val_loss: 0.6880\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 560ms/step - accuracy: 0.4239 - loss: 0.7211 - val_accuracy: 0.4400 - val_loss: 0.6928\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.5171 - loss: 0.6928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.5183 - loss: 0.6937 - val_accuracy: 0.6000 - val_loss: 0.6788\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - accuracy: 0.6329 - loss: 0.6645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 532ms/step - accuracy: 0.6241 - loss: 0.6676 - val_accuracy: 0.6000 - val_loss: 0.6777\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684ms/step - accuracy: 0.5109 - loss: 0.6905 - val_accuracy: 0.6000 - val_loss: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 03:52:28 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2025/03/12 03:52:28 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\u001b[31m2025/03/12 03:52:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Evaluating the model...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5787 - loss: 0.6865\n",
      "Evaluating completed.\n",
      "Saving the model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%run src/training_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_cxp1fcK-7H"
   },
   "source": [
    "#### Explore the Files\n",
    "\n",
    "The information will be logged to the `mlruns` directory.\n",
    "\n",
    "In our example the directory will have the following structure:\n",
    "\n",
    "```\n",
    "mlruns\n",
    "â””â”€â”€ <experiment ID>\n",
    "    â”œâ”€â”€ <Run Hash>\n",
    "    â”‚   â”œâ”€â”€ artifacts\n",
    "    â”‚   â”‚   â”œâ”€â”€ models\n",
    "    â”‚   â”‚   â””â”€â”€ run_info.txt\n",
    "    â”‚   â”œâ”€â”€ meta.yaml\n",
    "    â”‚   â”œâ”€â”€ metrics\n",
    "    â”‚   â”‚   â”œâ”€â”€ test_set_accuracy\n",
    "    â”‚   â”‚   â””â”€â”€ test_set_loss\n",
    "    â”‚   â”œâ”€â”€ params\n",
    "    â”‚   â”‚   â”œâ”€â”€ epochs\n",
    "    â”‚   â”‚   â”œâ”€â”€ img_size\n",
    "    â”‚   â”‚   â””â”€â”€ learning_rate\n",
    "    â”‚   â””â”€â”€ tags\n",
    "    â”‚       â”œâ”€â”€ mlflow.source.git.commit\n",
    "    â”‚       â”œâ”€â”€ mlflow.source.name\n",
    "    â”‚       â”œâ”€â”€ mlflow.source.type\n",
    "    â”‚       â””â”€â”€ mlflow.user\n",
    "    â””â”€â”€ meta.yaml\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrYrefNqLLzK"
   },
   "source": [
    "## â˜ï¸ Log Experiments to a Remote Tracking Server\n",
    "\n",
    "To avoide the long process of setting up a remote server,  we will use DagsHub integration with MLflow.\n",
    "\n",
    "When you create a repository on DagsHub, a remote MLflow server is automatically created and configured with the project. The repository's MLflow tracking server will be located at:\n",
    "\n",
    "`https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow`\n",
    "\n",
    "To set the remote server with you machine you need to:\n",
    "1. **Set DagsHub as the remote URI -**\n",
    "  * `mlflow.set_tracking_uri(\"https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow\")`\n",
    "2. **Set-up your credentials as OS variables**:\n",
    "  * `export MLFLOW_TRACKING_USERNAME=<DagsHub-user-name/token>`\n",
    "  * `export MLFLOW_TRACKING_PASSWORD=<password>`\n",
    "\n",
    "**Congratulations**, you are ready to start logging experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7KtpI0tNyNB"
   },
   "source": [
    "#### 1. Set up environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "CSznfaCFNmfO"
   },
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USER_NAME\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = f'https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO}.mlflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwYgCo93NYoj"
   },
   "source": [
    "#### 2. Create a new experiment on the remote server\n",
    "\n",
    "We will modify get_or_create_mlflow_experiment.py, and set the tracking URI\n",
    "\n",
    "```\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "\n",
    "def get_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "      exp_id = mlflow.create_experiment(name)\n",
    "      return exp_id\n",
    "    return exp.experiment_id\n",
    "\n",
    "print(get_experiment_id(\"mario_wario\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19MUlYxLpKGx",
    "outputId": "2c4e9be5-e5fc-4094-ca23-f0807fe1daf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "%run src/get_or_create_mlflow_experiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rcECrp3hrLe"
   },
   "source": [
    "#### 3. Modify the train.py script\n",
    "\n",
    "We will modify train.py, and set the tracking URI and set the new experiment id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Qe0SHgN50N"
   },
   "source": [
    "```\n",
    "# To be added to the top of train.py\n",
    "\n",
    "import os\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "# Recommended way:\n",
    "# mlflow.set_tracking_uri(\"https://dagshub.com/{user name}/{repo name}.mlflow\")\n",
    "\n",
    "# To be added in lime 93\n",
    "with mlflow.start_run(experiment_id=<experiment id>):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SBptQ5-zK-N"
   },
   "source": [
    "#### 4. Logging & visualizing the runs on remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "UtbLjJKSzubh",
    "outputId": "46e18e2b-0871-48fd-e461-8f6867f51010"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"https://dagshub.com/hddesai1/mario_vs_wario/experiments/#/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fadeef59010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "display(IPython.display.IFrame(f\"https://dagshub.com/hddesai1/mario_vs_wario/experiments/#/\",'100%',600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbEkavuGzmzg"
   },
   "source": [
    "#### 5. Re-running the code to see the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "Mpx81y7-N9i3",
    "outputId": "7183f25b-cc29-4d28-d9a5-4def269c9823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 images belonging to 2 classes.\n",
      "Found 25 images belonging to 2 classes.\n",
      "Found 45 images belonging to 2 classes.\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025/03/12 04:07:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3e2a94f08f784b02a5562b64e83ebebb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2025/03/12 04:07:33 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "2025/03/12 04:07:33 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - accuracy: 0.4417 - loss: 0.7084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4618 - loss: 0.7046 - val_accuracy: 0.6000 - val_loss: 0.6779\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 548ms/step - accuracy: 0.5371 - loss: 0.7008 - val_accuracy: 0.6000 - val_loss: 0.6835\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 504ms/step - accuracy: 0.5787 - loss: 0.6817 - val_accuracy: 0.6000 - val_loss: 0.6790\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.6196 - loss: 0.6728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 906ms/step - accuracy: 0.6153 - loss: 0.6719 - val_accuracy: 0.6000 - val_loss: 0.6730\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - accuracy: 0.5782 - loss: 0.6707"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5803 - loss: 0.6717 - val_accuracy: 0.6000 - val_loss: 0.6594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 04:07:53 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2025/03/12 04:07:53 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\u001b[31m2025/03/12 04:08:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run abrasive-tern-171 at: https://dagshub.com/hddesai1/mario_vs_wario.mlflow/#/experiments/0/runs/3e2a94f08f784b02a5562b64e83ebebb\n",
      "ğŸ§ª View experiment at: https://dagshub.com/hddesai1/mario_vs_wario.mlflow/#/experiments/0\n",
      "Training completed.\n",
      "Evaluating the model...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4125 - loss: 0.7173\n",
      "Evaluating completed.\n",
      "Saving the model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%run src/training_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Y9YshflFLn"
   },
   "source": [
    "## ğŸš– Logging all your information to a run with an Autologger!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV5rLMFT0Jx5"
   },
   "source": [
    "\n",
    "If you are a forgetful human logger like me who always forgets to log something to the TensorBoard or the outputs, you will probably appreciate this feature the most!\n",
    "\n",
    "Automatic logging allows you to log metrics, parameters, and models without the need for explicit log statements. MLFlow Autologger supports the following libraries :\n",
    "\n",
    "1. Scikit-learn\n",
    "2. TensorFlow and Keras\n",
    "3. Gluon\n",
    "4. XGBoost\n",
    "5. LightGBM\n",
    "6. Statsmodels\n",
    "7. Spark\n",
    "8. Fastai\n",
    "9. Pytorch\n",
    "\n",
    "While you can use `mlflow.autolog()` to enable logging for all the above supported libraries, alternatively you can use library-specific autolog calls for each library, letâ€™s use the specific autolog call for tensorflow :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km10q-b90Rid"
   },
   "source": [
    "Add ```mlflow.tensorflow.autolog()``` right above the call ```with mlflow.start_run():``` and re-run your code to see the logged metrics and artifacts with the autologger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "collapsed": true,
    "id": "HUW257oH2w35",
    "outputId": "6286ef22-4c3e-4b44-e4e0-801160dff5dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 images belonging to 2 classes.\n",
      "Found 25 images belonging to 2 classes.\n",
      "Found 45 images belonging to 2 classes.\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025/03/12 04:13:47 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "2025/03/12 04:13:47 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.5147 - loss: 0.7238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 691ms/step - accuracy: 0.5146 - loss: 0.7280 - val_accuracy: 0.6000 - val_loss: 0.6803\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: 0.5379 - loss: 0.6899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 898ms/step - accuracy: 0.5387 - loss: 0.6906 - val_accuracy: 0.6000 - val_loss: 0.6786\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 739ms/step - accuracy: 0.5984 - loss: 0.6822 - val_accuracy: 0.6000 - val_loss: 0.6798\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.6133 - loss: 0.6617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 574ms/step - accuracy: 0.6084 - loss: 0.6653 - val_accuracy: 0.6000 - val_loss: 0.6777\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.6067 - loss: 0.6755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706ms/step - accuracy: 0.6087 - loss: 0.6754 - val_accuracy: 0.6000 - val_loss: 0.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/12 04:14:03 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2025/03/12 04:14:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\u001b[31m2025/03/12 04:14:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Evaluating the model...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5831 - loss: 0.6838\n",
      "Evaluating completed.\n",
      "Saving the model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%run src/training_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljsreg3IZxTe"
   },
   "source": [
    "## **Saving the Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGw_sVoXZ23E",
    "outputId": "deef0d7f-8d37-4259-8129-35c93b762406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 03b8d39] added mlflow logging\n",
      " 2 files changed, 66 insertions(+), 27 deletions(-)\n",
      "Enumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 1.22 KiB | 1.22 MiB/s, done.\n",
      "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
      "To https://dagshub.com/hddesai1/mario_vs_wario.git\n",
      "   8358cbf..03b8d39  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"added mlflow logging\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbEtnQqq9YDV"
   },
   "source": [
    "# ğŸ‰ **Congratulations!**\n",
    "\n",
    "You can now integrate MLFlow's experiment tracking to all your projects!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}